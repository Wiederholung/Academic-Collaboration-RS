{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.dao import db_utils as db\n",
    "\n",
    "# 载入张量\n",
    "all_sim = torch.load(\"res/all_sim-300d.pt\")\n",
    "avs = torch.load('res/author_vec_set.pt')\n",
    "avs_2d = torch.load(\"res/author_vec_set-2d.pt\")\n",
    "\n",
    "# 定义变量\n",
    "author_set = db.get_all_name_en()\n",
    "\n",
    "print(\"Jupyter: ACRS on Position!\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(all_sim)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# all_sim.pt to csv\n",
    "# 填充对称矩阵\n",
    "for i in range(len(author_set)):\n",
    "    for j in range(len(author_set)):\n",
    "        all_sim[j][i] = all_sim[i][j]\n",
    "pd.DataFrame(all_sim.numpy(), columns=author_set, index=author_set).to_csv(\"res/all_sim-300d.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# author_vec_set.pt to csv\n",
    "pd.DataFrame(avs.numpy(), index=author_set).to_csv(\"res/author_vec_set.csv\")\n",
    "pd.DataFrame(avs_2d, index=author_set).to_csv(\"res/author_vec_set-2d.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "centers = [[20, 1], [-2, -1], [2, -1]]  # 三个中心点的坐标\n",
    "# datas为样本数据集，labels_true为样本数据集的标签\n",
    "datas, labels_true = make_blobs(n_samples=750, centers=centers, cluster_std=0.4,\n",
    "                                random_state=0)\n",
    "print(type(datas))\n",
    "print(datas.shape)\n",
    "print(datas)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "UNCLASSIFIED = 0  # 点未被标记\n",
    "NOISE = -1  # 噪声点标记\n",
    "\n",
    "\n",
    "# 计算数据点两两之间的距离\n",
    "def getDistanceMatrix(datas):  # datas 是聚类数据\n",
    "    N, D = np.shape(datas)  # 读取datas的维度，维度是N x D（N指数据个数，D指特征维度）   ，shape函数用于获取矩阵的形状\n",
    "    dists = np.zeros([N, N])  # zeros 函数：返回一个给定形状和类型的用0填充的数组，\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            vi = datas[i, :]  # 切片 [开始,结束]\n",
    "            vj = datas[j, :]\n",
    "            dists[i, j] = np.sqrt(np.dot((vi - vj), (vi - vj)))  # 欧式距离函数,返回点与点之间距离的数组\n",
    "    return dists\n",
    "\n",
    "\n",
    "#  寻找以点cluster_id 为中心，eps 为半径的圆内的所有点的id\n",
    "def find_points_in_eps(point_id, eps, dists):\n",
    "    index = dists[point_id] <= eps  # dists[point_id] 即：point_id 与 所有点的距离\n",
    "    return np.where(index)[0].tolist()  # 返回所有符合的点的集合\n",
    "\n",
    "\n",
    "def expand_cluster(dists, labs, cluster_id, seeds, eps, min_points):\n",
    "    \"\"\"\n",
    "    聚类扩展\n",
    "    :param dists: 任意数据两两之间的距离  N x N\n",
    "    :param labs: 所有数据的标签 labs N\n",
    "    :param cluster_id: 一个簇的标号\n",
    "    :param seeds: 密度评估半径\n",
    "    :param eps: 用来进行簇扩展的点\n",
    "    :param min_points: 半径内最少的点数\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    while i < len(seeds):\n",
    "        Pn = seeds[i]  # 获取一个点\n",
    "        if labs[Pn] == NOISE:  # 如果是噪声点，则重新标记\n",
    "            labs[Pn] = cluster_id\n",
    "        elif labs[Pn] == UNCLASSIFIED:  # 如果未被标记过，则进行标记\n",
    "            labs[Pn] = cluster_id\n",
    "            new_seeds = find_points_in_eps(Pn, eps, dists)  # 以新点为圆心再画圈，进行扩展\n",
    "            if len(new_seeds) >= min_points:  # 如果扩张的圈中数够多，则加入到seeds队列中\n",
    "                seeds = seeds + new_seeds\n",
    "        i += 1\n",
    "        # 通过挨个标记和扩展seeds里的数字，实现聚类过程\n",
    "\n",
    "\n",
    "def dbscan(datas, eps, min_points):\n",
    "    dists = getDistanceMatrix(datas)  # 获取点与点之间的距离，且以二维数组的形式\n",
    "    # 将所有点的标签初始化为0\n",
    "    n_points = datas.shape[0]  # shape[0]指读取读取矩阵第一维的长度\n",
    "    labs = [UNCLASSIFIED] * n_points\n",
    "\n",
    "    cluster_id = 0\n",
    "    # 遍历所有点\n",
    "    for point_id in range(n_points):\n",
    "        if labs[point_id] != UNCLASSIFIED:  # 如果被标记，则结束此次循环，表示该点已处理过\n",
    "            continue  # 没有处理过，则计算寻找临近点\n",
    "        seeds = find_points_in_eps(point_id, eps, dists)  # 符合条件的点存到seeds中\n",
    "\n",
    "        if len(seeds) < min_points:  # 如果临近点过少，则标记为噪声点\n",
    "            labs[point_id] = NOISE\n",
    "        else:  # 否则开启新一轮扩张\n",
    "            cluster_id = cluster_id + 1\n",
    "            labs[point_id] = cluster_id  # 标记当前点\n",
    "            expand_cluster(dists, labs, cluster_id, seeds, eps, min_points)\n",
    "    return labs, cluster_id\n",
    "\n",
    "\n",
    "def draw_cluster(datas, labs, n_cluster):\n",
    "    \"\"\"\n",
    "    绘图\n",
    "    :param datas: 数据\n",
    "    :param labs: 聚类结果\n",
    "    :param n_cluster: 聚类个数\n",
    "    :return: 绘图\n",
    "    \"\"\"\n",
    "    plt.cla()\n",
    "    # 设计颜色\n",
    "    colors = [plt.cm.Spectral(each)\n",
    "              for each in np.linspace(0, 1, n_cluster)]  # (起点，终点，几个元素)\n",
    "\n",
    "    # 遍历所有点的坐标\n",
    "    for i, lab in enumerate(labs):\n",
    "        if lab == NOISE:  # 如果是噪声点 则为黑色\n",
    "            plt.scatter(datas[i, 0], datas[i, 1], s=16., color=(0, 0, 0))\n",
    "        else:  # 否则，根据类别的编号，来标记颜色\n",
    "            plt.scatter(datas[i, 0], datas[i, 1], s=16., color=colors[lab - 1])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "## 数据1\n",
    "# centers = [[20, 1], [-2, -1], [2, -1]]  # 三个中心点的坐标\n",
    "# # datas为样本数据集，labels_true为样本数据集的标签\n",
    "# datas, labels_true = make_blobs(n_samples=750, centers=centers, cluster_std=0.4,\n",
    "#                                 random_state=0)\n",
    "# 产生一组随机数datas，中心点是centers，方差是0.4，产生750个点\n",
    "\n",
    "## 数据2\n",
    "# file_name = \"spiral\"\n",
    "# with open(file_name+\".txt\",\"r\",encoding=\"utf-8\") as f:\n",
    "#    lines = f.read().splitlines()\n",
    "# lines = [line.split(\"\\t\")[:-1] for line in lines]\n",
    "# datas = np.array(lines).astype(np.float32)\n",
    "\n",
    "\n",
    "# 数据正则化，让参与的数据减去均值出方差，是临均值，标准差成了1\n",
    "datas = StandardScaler().fit_transform(avs_2d)  # 计算训练数据的均值和方差，并基于计算出来的均值和方差来转换训练数据，从而把数据转换成标准的正态分布\n",
    "eps = 0.35\n",
    "min_points = 5\n",
    "\n",
    "# 手动实现DBSCAN\n",
    "# dbscan算法，labs是最终结果，cluster_num 是分成了多少类\n",
    "labs, cluster_num = dbscan(datas, eps=eps, min_points=min_points)\n",
    "# print(\"labs of my dbscan\")\n",
    "# print(labs)\n",
    "\n",
    "# sklearn里的DBSCAN 算法\n",
    "# 分类器     # 半径      min_points           对datas进行聚类\n",
    "clustering = DBSCAN(eps=eps, min_samples=min_points).fit(datas)\n",
    "skl_labels = clustering.labels_\n",
    "# print(\"labs of sk-DBSCAN\")\n",
    "# print(skl_labels)\n",
    "# 画出\n",
    "print(\"上方为datas表格-------------------------------\")\n",
    "draw_cluster(datas, skl_labels, cluster_num)\n",
    "\n",
    "# dbscan 输出，123表示聚类点，-1表示噪声点\n",
    "# sklearn 输出  012表示聚类点，-1表示噪声点\n",
    "print(skl_labels)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 将 cluster_id 与学者对应并保存 csv\n",
    "a = np.array(author_set)[:,np.newaxis]  # 转置\n",
    "s = np.array(skl_labels)[:,np.newaxis]\n",
    "res = np.hstack((a,s,datas))\n",
    "pd.DataFrame(res, columns=['author', 'cluster_id','x','y'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "center = []\n",
    "for i in range(cluster_num):\n",
    "    center.append(np.mean(datas[skl_labels == i], axis=0))\n",
    "center = np.array(center)\n",
    "print(center)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 获取噪声点的坐标\n",
    "noise = datas[skl_labels == -1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 计算距离公式为：\n",
    "\n",
    "$$\n",
    "(x-x_{center})^2+(y-y_{center})^2\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "> 注意：\n",
    "在使用Numpy时，如果array后面加了condition，则**无法直接修改其内容**（应该是算法没有实现记录对应的index，耽误了好久时间...）"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 记录每个噪声点在res中的索引"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "noise_index = []\n",
    "print(skl_labels)\n",
    "for i in range(len(skl_labels)):\n",
    "    if skl_labels[i] == -1:\n",
    "        noise_index.append(i)\n",
    "print(noise_index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 利用上述公式，计算距离，根据距离修改标签"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(len(noise)):\n",
    "    dis = np.sum((noise[i] - center) ** 2, axis=1)\n",
    "    #argmin返回最小值的索引\n",
    "    res = np.argmin(dis)\n",
    "    #将噪声点的skl_labels改为最近的簇的skl_labels\n",
    "    index=noise_index[i]\n",
    "    skl_labels[index] = res"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 更新后的标签"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(skl_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 更新后的表格"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = np.array(author_set)[:, np.newaxis]  # 转置\n",
    "s = np.array(skl_labels)[:, np.newaxis]\n",
    "res = np.hstack((a, s, datas))\n",
    "pd.DataFrame(res, columns=['author', 'cluster_id', 'x', 'y'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 更新后的图"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "draw_cluster(datas, skl_labels, cluster_num)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame(res, columns=['author', 'cluster_id', 'x', 'y']).to_csv('res/cluster_result.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}